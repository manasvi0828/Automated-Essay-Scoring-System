{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f316029-4cf9-445f-ab8a-3d030c19cffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras-Preprocessing in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from Keras-Preprocessing) (1.26.4)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from Keras-Preprocessing) (1.16.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MANASVI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "!pip install Keras-Preprocessing\n",
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, SpatialDropout1D\n",
    "from keras.optimizers import Adam\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b858f9b-c769-45c3-a870-05e0007c11d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your essay data\n",
    "data = pd.read_csv(\"dataset.tsv\", sep='\\t', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19766a0f-5fe7-4cdb-9b57-9f72c8d3dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to essays\n",
    "data['processed_essay'] = data['essay'].apply(preprocess_text)\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['processed_essay'].values)\n",
    "X = tokenizer.texts_to_sequences(data['processed_essay'].values)\n",
    "X = pad_sequences(X, maxlen=500)  # Assume maximum length of essay is 500 tokens\n",
    "\n",
    "# Prepare target variable\n",
    "y = data['domain1_score'].values\n",
    "\n",
    "# Train Word2Vec model\n",
    "w2v_model = Word2Vec(data['processed_essay'].apply(lambda x: x.split()), vector_size=100, window=5, min_count=2, workers=4)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f4edc1-6322-4058-882b-87b78c44f8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANASVI\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=500, trainable=False))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb2c7287-e280-4a5a-8da6-7d4013759d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "163/163 - 145s - 889ms/step - loss: 58.4353 - mean_absolute_error: 4.3038 - val_loss: 25.9194 - val_mean_absolute_error: 2.4441\n",
      "Epoch 2/5\n",
      "163/163 - 133s - 816ms/step - loss: 28.9097 - mean_absolute_error: 2.8455 - val_loss: 14.9623 - val_mean_absolute_error: 2.0701\n",
      "Epoch 3/5\n",
      "163/163 - 137s - 841ms/step - loss: 13.7784 - mean_absolute_error: 2.0632 - val_loss: 7.4325 - val_mean_absolute_error: 1.5822\n",
      "Epoch 4/5\n",
      "163/163 - 136s - 837ms/step - loss: 8.0012 - mean_absolute_error: 1.6588 - val_loss: 13.3034 - val_mean_absolute_error: 1.8633\n",
      "Epoch 5/5\n",
      "163/163 - 136s - 833ms/step - loss: 6.6797 - mean_absolute_error: 1.6011 - val_loss: 4.2055 - val_mean_absolute_error: 1.2633\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(), metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_val, y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7997e3b-2f38-4887-b03c-ab37dbcbf8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step\n",
      "[[ 1.0465763]\n",
      " [ 1.2016009]\n",
      " [ 8.597796 ]\n",
      " ...\n",
      " [ 9.877499 ]\n",
      " [ 2.3862283]\n",
      " [37.728992 ]]\n",
      "R^2 Score: 0.9459846989013149\n",
      "Validation Mean Absolute Error: 1.2633219671669562\n",
      "Validation Mean Squared Error: 4.205516938330287\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_val)\n",
    "print(y_pred)\n",
    "\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(f'R^2 Score: {r2}')\n",
    "\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "print(f'Validation Mean Absolute Error: {mae}')\n",
    "\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "print(f'Validation Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85f9fcef-5023-4286-8859-6795d073a1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Score: 3.7132339477539062\n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess and predict score for a new essay\n",
    "def predict_score(new_essay, model, tokenizer, max_length=500):\n",
    "    processed_essay = preprocess_text(new_essay)\n",
    "    sequence = tokenizer.texts_to_sequences([processed_essay])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_length)\n",
    "    predicted_score = model.predict(padded_sequence, verbose=0)\n",
    "    return predicted_score[0][0]\n",
    "\n",
    "# Predict grade for a new essay\n",
    "new_essay = \"Reading opens doors to new worlds and ideas. It enriches the mind and broadens perspectives. Whether fiction or non-fiction, books offer endless opportunities for learning and imagination. They entertain, educate, and inspire. In a busy world, reading provides a tranquil escape, fostering growth and creativity in every reader.\"\n",
    "predicted_score = predict_score(new_essay, model, tokenizer)\n",
    "print(f\"Predicted Score: {predicted_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "682c992a-01af-41a9-b859-d77ec059a633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "import pickle\n",
    "model.save('models/essay_scoring_model.h5')\n",
    "\n",
    "# Save the tokenizer\n",
    "with open('models/tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Model and tokenizer saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa8aeb-7973-430d-9345-74ce7d1a1d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
