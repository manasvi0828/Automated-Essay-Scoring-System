{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020c5a3a-dd23-43e8-a6a9-2236191e0d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff98a0d2-bfc3-442d-90db-8a8c20b7863c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "3             NaN             NaN            NaN  ...            NaN   \n",
       "4             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.tsv', sep='\\t', encoding='ISO-8859-1');\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bd24476-e97a-4079-8c3b-ff7dac1b370e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10684</th>\n",
       "      <td>17834</td>\n",
       "      <td>7</td>\n",
       "      <td>Patience is when your waiting .I was patience ...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10685</th>\n",
       "      <td>17836</td>\n",
       "      <td>7</td>\n",
       "      <td>I am not a patience person, like I canÂ’t sit i...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10686</th>\n",
       "      <td>17837</td>\n",
       "      <td>7</td>\n",
       "      <td>One day I was at basketball practice and I was...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10687</th>\n",
       "      <td>17838</td>\n",
       "      <td>7</td>\n",
       "      <td>I going to write about a time when I went to t...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10688</th>\n",
       "      <td>17839</td>\n",
       "      <td>7</td>\n",
       "      <td>It can be very hard for somebody to be patient...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12248</th>\n",
       "      <td>19558</td>\n",
       "      <td>7</td>\n",
       "      <td>One time I was getting a cool @CAPS1 game it w...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12249</th>\n",
       "      <td>19559</td>\n",
       "      <td>7</td>\n",
       "      <td>A patent person in my life is my mom. Aicason ...</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12250</th>\n",
       "      <td>19561</td>\n",
       "      <td>7</td>\n",
       "      <td>A time when someone else I know was patient wa...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12251</th>\n",
       "      <td>19562</td>\n",
       "      <td>7</td>\n",
       "      <td>I hate weddings. I love when people get marrie...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12252</th>\n",
       "      <td>19563</td>\n",
       "      <td>7</td>\n",
       "      <td>A few weeks ago, we had a garage sale and a mo...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1569 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id  essay_set                                              essay  \\\n",
       "10684     17834          7  Patience is when your waiting .I was patience ...   \n",
       "10685     17836          7  I am not a patience person, like I canÂ’t sit i...   \n",
       "10686     17837          7  One day I was at basketball practice and I was...   \n",
       "10687     17838          7  I going to write about a time when I went to t...   \n",
       "10688     17839          7  It can be very hard for somebody to be patient...   \n",
       "...         ...        ...                                                ...   \n",
       "12248     19558          7  One time I was getting a cool @CAPS1 game it w...   \n",
       "12249     19559          7  A patent person in my life is my mom. Aicason ...   \n",
       "12250     19561          7  A time when someone else I know was patient wa...   \n",
       "12251     19562          7  I hate weddings. I love when people get marrie...   \n",
       "12252     19563          7  A few weeks ago, we had a garage sale and a mo...   \n",
       "\n",
       "       rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "10684               8               7             NaN             15   \n",
       "10685               6               7             NaN             13   \n",
       "10686               7               8             NaN             15   \n",
       "10687               8               9             NaN             17   \n",
       "10688               7               6             NaN             13   \n",
       "...               ...             ...             ...            ...   \n",
       "12248               6               6             NaN             12   \n",
       "12249               9               7             NaN             16   \n",
       "12250              11               8             NaN             19   \n",
       "12251              12              10             NaN             22   \n",
       "12252               7               8             NaN             15   \n",
       "\n",
       "       rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "10684             NaN             NaN            NaN  ...            2.0   \n",
       "10685             NaN             NaN            NaN  ...            2.0   \n",
       "10686             NaN             NaN            NaN  ...            2.0   \n",
       "10687             NaN             NaN            NaN  ...            2.0   \n",
       "10688             NaN             NaN            NaN  ...            1.0   \n",
       "...               ...             ...            ...  ...            ...   \n",
       "12248             NaN             NaN            NaN  ...            2.0   \n",
       "12249             NaN             NaN            NaN  ...            2.0   \n",
       "12250             NaN             NaN            NaN  ...            2.0   \n",
       "12251             NaN             NaN            NaN  ...            2.0   \n",
       "12252             NaN             NaN            NaN  ...            2.0   \n",
       "\n",
       "       rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  \\\n",
       "10684            2.0            NaN            NaN            NaN   \n",
       "10685            1.0            NaN            NaN            NaN   \n",
       "10686            2.0            NaN            NaN            NaN   \n",
       "10687            3.0            NaN            NaN            NaN   \n",
       "10688            2.0            NaN            NaN            NaN   \n",
       "...              ...            ...            ...            ...   \n",
       "12248            1.0            NaN            NaN            NaN   \n",
       "12249            3.0            NaN            NaN            NaN   \n",
       "12250            2.0            NaN            NaN            NaN   \n",
       "12251            3.0            NaN            NaN            NaN   \n",
       "12252            2.0            NaN            NaN            NaN   \n",
       "\n",
       "       rater3_trait2  rater3_trait3  rater3_trait4  rater3_trait5  \\\n",
       "10684            NaN            NaN            NaN            NaN   \n",
       "10685            NaN            NaN            NaN            NaN   \n",
       "10686            NaN            NaN            NaN            NaN   \n",
       "10687            NaN            NaN            NaN            NaN   \n",
       "10688            NaN            NaN            NaN            NaN   \n",
       "...              ...            ...            ...            ...   \n",
       "12248            NaN            NaN            NaN            NaN   \n",
       "12249            NaN            NaN            NaN            NaN   \n",
       "12250            NaN            NaN            NaN            NaN   \n",
       "12251            NaN            NaN            NaN            NaN   \n",
       "12252            NaN            NaN            NaN            NaN   \n",
       "\n",
       "       rater3_trait6  \n",
       "10684            NaN  \n",
       "10685            NaN  \n",
       "10686            NaN  \n",
       "10687            NaN  \n",
       "10688            NaN  \n",
       "...              ...  \n",
       "12248            NaN  \n",
       "12249            NaN  \n",
       "12250            NaN  \n",
       "12251            NaN  \n",
       "12252            NaN  \n",
       "\n",
       "[1569 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['essay_set']==7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdb08eaf-58bd-41ad-939f-33728f4edf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0404503-d1a7-4120-a617-457794b4f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['rater1_domain1','rater2_domain1'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce2f5016-02de-4270-ba2b-25233b3aa3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1783    4\n",
       "1784    1\n",
       "1785    2\n",
       "1786    4\n",
       "1787    4\n",
       "       ..\n",
       "3578    3\n",
       "3579    3\n",
       "3580    2\n",
       "3581    3\n",
       "3582    3\n",
       "Name: domain1_score, Length: 1800, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['essay_set']==2]['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26bf7f2b-5177-445a-b53d-bc7ac54961ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_range = [2,1,0,0,0,0,0,0]\n",
    "max_range = [12,6,3,3,4,4,30,60]\n",
    "\n",
    "def normalize(x,mi,ma):\n",
    "    #print(\"Before Normalization: \"+str(x))\n",
    "    x = (x-mi)/(ma-mi)\n",
    "    #print(\"After Normalization : \"+str(x))\n",
    "    return round(x*10)\n",
    "\n",
    "df['final_score']=df.apply(lambda x:normalize(x['domain1_score'],min_range[x['essay_set']-1],max_range[x['essay_set']-1]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba2fd54-1927-4667-b43c-ee363a14251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('domain1_score',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c78b9aa9-b873-4041-99fe-efa0ba20a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_essay(essay):\n",
    "    x=[]\n",
    "    for i in essay.split():\n",
    "        if i.startswith(\"@\"):\n",
    "            continue\n",
    "        else:\n",
    "            x.append(i)\n",
    "    return ' '.join(x)\n",
    "\n",
    "df['essay'] = df['essay'].apply(lambda x:clean_essay(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31892aed-a78e-4305-9a43-5240cabe1656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MANASVI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english')) \n",
    "def remove_stop_words(essay):\n",
    "    word_tokens = word_tokenize(essay) \n",
    "    filtered_sentence = [] \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "df['clean_essay'] = df['essay'].apply(lambda x:remove_stop_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "943a7c46-90ca-4da4-8b3d-4938c1c1e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_puncs(essay):\n",
    "    essay = re.sub(\"[^A-Za-z ]\",\"\",essay)\n",
    "    return essay\n",
    "\n",
    "df['clean_essay'] = df['clean_essay'].apply(lambda x:remove_puncs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b0fdd11-245c-4ca3-b2f3-999ce49eedac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2word(x):\n",
    "    x=re.sub(\"[^A-Za-z0-9]\",\" \",x)\n",
    "    words=nltk.word_tokenize(x)\n",
    "    return words\n",
    "\n",
    "def essay2word(essay):\n",
    "    essay = essay.strip()\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw = tokenizer.tokenize(essay)\n",
    "    final_words=[]\n",
    "    for i in raw:\n",
    "        if(len(i)>0):\n",
    "            final_words.append(sent2word(i))\n",
    "    return final_words\n",
    "        \n",
    "\n",
    "def noOfWords(essay):\n",
    "    count=0\n",
    "    for i in essay2word(essay):\n",
    "        count=count+len(i)\n",
    "    return count\n",
    "\n",
    "def noOfChar(essay):\n",
    "    count=0\n",
    "    for i in essay2word(essay):\n",
    "        for j in i:\n",
    "            count=count+len(j)\n",
    "    return count\n",
    "\n",
    "def avg_word_len(essay):\n",
    "    return noOfChar(essay)/noOfWords(essay)\n",
    "\n",
    "def noOfSent(essay):\n",
    "    return len(essay2word(essay))\n",
    "\n",
    "def count_pos(essay):\n",
    "    sentences = essay2word(essay)\n",
    "    noun_count=0\n",
    "    adj_count=0\n",
    "    verb_count=0\n",
    "    adverb_count=0\n",
    "    for i in sentences:\n",
    "        pos_sentence = nltk.pos_tag(i)\n",
    "        for j in pos_sentence:\n",
    "            pos_tag = j[1]\n",
    "            if(pos_tag[0]=='N'):\n",
    "                noun_count+=1\n",
    "            elif(pos_tag[0]=='V'):\n",
    "                verb_count+=1\n",
    "            elif(pos_tag[0]=='J'):\n",
    "                adj_count+=1\n",
    "            elif(pos_tag[0]=='R'):\n",
    "                adverb_count+=1\n",
    "    return noun_count,verb_count,adj_count,adverb_count\n",
    "\n",
    "data = open('big.txt').read()\n",
    "words = re.findall('[a-z]+', data.lower())\n",
    "\n",
    "def check_spell_error(essay):\n",
    "    essay=essay.lower()\n",
    "    new_essay = re.sub(\"[^A-Za-z0-9]\",\" \",essay)\n",
    "    new_essay = re.sub(\"[0-9]\",\"\",new_essay)\n",
    "    count=0\n",
    "    all_words = new_essay.split()\n",
    "    for i in all_words:\n",
    "        if i not in words:\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fc4af93-7dfa-42e4-bcff-24b94ec63359",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features = 10000, ngram_range=(1, 3), stop_words='english')\n",
    "count_vectors = vectorizer.fit_transform(df['clean_essay'])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "data = df[['essay_set','clean_essay','final_score']].copy()\n",
    "X = count_vectors.toarray()\n",
    "y = data['final_score'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79676327-2826-4862-a3d3-49c8bed6274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_data = df.copy()\n",
    "pro_data['char_count'] = pro_data['essay'].apply(noOfChar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24d43bcc-01ea-4471-867a-7309a4b537e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_data['word_count'] = pro_data['essay'].apply(noOfWords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4e637c8-b697-4d7e-9566-1e2f891ed9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_data['sent_count'] = pro_data['essay'].apply(noOfSent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bf75194-fc7c-4489-9aac-d2693c6d9833",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_data['avg_word_len'] = pro_data['essay'].apply(avg_word_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67915c5-d407-4aee-a665-f72e89cc7bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting swifter\n",
      "  Downloading swifter-1.4.0.tar.gz (1.2 MB)\n",
      "     ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/1.2 MB 162.5 kB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.1/1.2 MB 327.7 kB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 0.3/1.2 MB 1.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 1.1/1.2 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.2/1.2 MB 4.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from swifter) (2.1.4)\n",
      "Requirement already satisfied: psutil>=5.6.6 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from swifter) (5.9.0)\n",
      "Requirement already satisfied: dask>=2.10.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (2023.11.0)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from swifter) (4.65.0)\n",
      "Requirement already satisfied: click>=8.1 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (2.2.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (23.1)\n",
      "Requirement already satisfied: partd>=1.2.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (7.0.1)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->swifter) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->swifter) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->swifter) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->swifter) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from tqdm>=4.33.0->swifter) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.13.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (3.17.0)\n",
      "Requirement already satisfied: locket in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from partd>=1.2.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\manasvi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->swifter) (1.16.0)\n",
      "Building wheels for collected packages: swifter\n",
      "  Building wheel for swifter (setup.py): started\n",
      "  Building wheel for swifter (setup.py): finished with status 'done'\n",
      "  Created wheel for swifter: filename=swifter-1.4.0-py3-none-any.whl size=16513 sha256=578519b42feb3a887fbc0a9a8002da6aa9d9d507e9d3cf73d7b3796d7fe4c09f\n",
      "  Stored in directory: c:\\users\\manasvi\\appdata\\local\\pip\\cache\\wheels\\ef\\7f\\bd\\9bed48f078f3ee1fa75e0b29b6e0335ce1cb03a38d3443b3a3\n",
      "Successfully built swifter\n",
      "Installing collected packages: swifter\n",
      "Successfully installed swifter-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install swifter\n",
    "import pandas as pd\n",
    "import swifter\n",
    "\n",
    "# Assume pro_data is your DataFrame and check_spell_error is your function\n",
    "pro_data['spell_err_count'] = pro_data['essay'].swifter.apply(check_spell_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990fa378-c3dc-46d6-9e42-f5c24509060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_data['noun_count'], pro_data['adj_count'], pro_data['verb_count'], pro_data['adv_count'] = zip(*pro_data['essay'].map(count_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee765a81-7e47-463e-9a79-c6cf5a31adad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_data.to_csv(\"Processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954b1a29-eaf6-4662-965f-711803e6fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df = pd.read_csv(\"Processed_data.csv\")\n",
    "prep_df.drop('Unnamed: 0',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55081878-0b1d-49cc-bccf-76b5205d7111",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features = 10000, ngram_range=(1, 3), stop_words='english')\n",
    "count_vectors = vectorizer.fit_transform(prep_df['clean_essay'])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "X = count_vectors.toarray()\n",
    "X_full = np.concatenate((prep_df.iloc[:, 5:].as_matrix(), X), axis = 1)\n",
    "y_full = prep_df['final_score'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a31821-f09b-4701-bbc4-942b8d05e193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Trained Model\n",
    "# clf = SVR(C=1.0, epsilon=0.2)\n",
    "# clf.fit(X_train, y_train)\n",
    "# pickle.dump(clf,open(\"Saved_Models/SVR_with_pp\",'wb'))\n",
    "\n",
    "#Use Saved Model\n",
    "clf = pickle.load(open('Saved_Models/SVR_with_pp', 'rb'))\n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Mean squared error:%.2f\"%mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b332e3-3db0-4c84-aaf4-cd5cd1654623",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Trained Model\n",
    "# rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# rf.fit(X_train, y_train)\n",
    "# pickle.dump(rf, open('Saved_Models/RF_with_PP', 'wb'))\n",
    "\n",
    "#Use Saved Model\n",
    "rf = pickle.load(open('Saved_Models/RF_wth_pp', 'rb'))\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
